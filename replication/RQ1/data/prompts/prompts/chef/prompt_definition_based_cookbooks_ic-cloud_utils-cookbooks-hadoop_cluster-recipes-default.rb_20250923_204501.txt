# CONSTRUCTED PROMPT
# File: cookbooks_ic-cloud_utils-cookbooks-hadoop_cluster-recipes-default.rb
# Style: definition_based
# Timestamp: 2025-09-23T20:45:01.358412
# Length: 9398 characters
# ============================================================

You are an expert in Infrastructure-as-Code (IaC) security analysis.

Your task is to analyze the **raw code** of an IaC script and detect any **security smells** according to the definitions and patterns described below.

You must parse the script internally, identify patterns, and output a list of security smells with corresponding line numbers.

---

### SECURITY SMELL DEFINITIONS

1. **Admin by default**: This smell is the recurring pattern of specifying default users as administrative users. The smell can violate the "principle of least privilege" property. We can consider this smell every time more privileges are being given than it should be necessary.

2. **Empty password**: This smell is the recurring pattern of using a string of length zero for a password. An empty password is indicative of a weak password.

3. **Hard-coded secret**: This smell is the recurring pattern of revealing sensitive information, such as user name and passwords in IaC scripts. We consider three types of hard-coded secrets: hard-coded passwords, hard-coded user names, and hard-coded private cryptography keys.

4. **Missing Default in Case Statement**: This smell is the recurring pattern of not handling all input combinations when implementing a case conditional logic.

5. **No integrity check**: This smell is the recurring pattern of downloading content from the Internet and not checking the downloaded content using checksums or gpg signatures. Simply referencing or defining a URL does not count unless an actual download is performed without validation.

6. **Suspicious comment**: This smell is the recurring pattern of putting information in comments about the presence of defects, missing functionality, or weakness of the system. Examples of such comments include putting keywords such as "TODO," "FIXME," and "HACK" in comments.

7. **Unrestricted IP Address**: This smell is the recurring pattern of assigning the address 0.0.0.0 for a database server or a cloud service/instance. Binding to the address 0.0.0.0 may cause security concerns as this address can allow connections from every possible network.

8. **Use of HTTP without SSL/TLS**: This smell is the recurring pattern of using HTTP without the Transport Layer Security (TLS) or Secure Sockets Layer (SSL). Such use makes the communication between two entities less secure, as without SSL/TLS, use of HTTP is susceptible to man-in-the-middle attacks. Do not flag http:// URLs that use local addresses like localhost, 127.0.0.1, or ::1, as these are not security risks.

9. **Use of weak cryptography algorithms**: This smell is the recurring pattern of using weak cryptography algorithms, namely, MD5 and SHA-1, for encryption purposes.

---

### INSTRUCTIONS

1. Analyze the following **raw IaC code** line-by-line.
2. For each detected smell, identify:
   - The exact line number where the smell occurs
   - The specific security smell category from the definitions above
   - The problematic code pattern

If no smells are found, indicate that no issues were detected.

---

### RAW CODE INPUT

**Analyzing file: cookbooks_ic-cloud_utils-cookbooks-hadoop_cluster-recipes-default.rb (Unknown)**


Line 1: #
Line 2: # Cookbook Name::       hadoop_cluster
Line 3: # Description::         Base configuration for hadoop_cluster
Line 4: # Recipe::              default
Line 5: # Author::              Philip (flip) Kromer - Infochimps, Inc
Line 6: #
Line 7: # Copyright 2009, Opscode, Inc.
Line 8: #
Line 9: # Licensed under the Apache License, Version 2.0 (the "License");
Line 10: # you may not use this file except in compliance with the License.
Line 11: # You may obtain a copy of the License at
Line 12: #
Line 13: #     http://www.apache.org/licenses/LICENSE-2.0
Line 14: #
Line 15: # Unless required by applicable law or agreed to in writing, software
Line 16: # distributed under the License is distributed on an "AS IS" BASIS,
Line 17: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
Line 18: # See the License for the specific language governing permissions and
Line 19: # limitations under the License.
Line 20: #
Line 21: 
Line 22: include_recipe 'java' ; complain_if_not_sun_java(:hadoop)
Line 23: include_recipe 'volumes'
Line 24: class Chef::Recipe; include HadoopCluster ; end
Line 25: 
Line 26: include_recipe 'silverware'
Line 27: include_recipe 'tuning'
Line 28: include_recipe 'hadoop_cluster::add_cloudera_repo'
Line 29: 
Line 30: #
Line 31: # Hadoop users and group
Line 32: #
Line 33: 
Line 34: daemon_user(:hadoop){ user(:hdfs)   }
Line 35: daemon_user(:hadoop){ user(:mapred) }
Line 36: 
Line 37: group 'hadoop' do
Line 38:   group_name 'hadoop'
Line 39:   gid         node[:groups]['hadoop'][:gid]
Line 40:   action      [:create, :manage]
Line 41:   append     true
Line 42:   members     ['hdfs', 'mapred']
Line 43: end
Line 44: 
Line 45: # Create the group hadoop uses to mean 'can act as filesystem root'
Line 46: group 'supergroup' do
Line 47:   group_name 'supergroup'
Line 48:   gid        node[:groups]['supergroup'][:gid]
Line 49:   action     [:create, :manage]
Line 50:   append     true
Line 51: end
Line 52: 
Line 53: #
Line 54: # Primary hadoop packages
Line 55: #
Line 56: # (do this *after* creating the users)
Line 57: 
Line 58: hadoop_package nil
Line 59: hadoop_package "native"
Line 60: hadoop_package "sbin"
Line 61: 
Line 62: #
Line 63: # Hadoop directories
Line 64: #
Line 65: #
Line 66: 
Line 67: standard_dirs('hadoop') do
Line 68:   directories   :conf_dir, :pid_dir
Line 69: end
Line 70: 
Line 71: # Namenode metadata striped across all persistent dirs
Line 72: volume_dirs('hadoop.namenode.data') do
Line 73:   type          :persistent
Line 74:   selects       :all
Line 75:   path          'hadoop/hdfs/name'
Line 76:   mode          "0700"
Line 77: end
Line 78: 
Line 79: # Secondary Namenode metadata striped across all persistent dirs
Line 80: volume_dirs('hadoop.secondarynn.data') do
Line 81:   type          :persistent
Line 82:   selects       :all
Line 83:   path          'hadoop/hdfs/secondary'
Line 84:   mode          "0700"
Line 85: end
Line 86: 
Line 87: # Datanode data striped across all persistent dirs
Line 88: volume_dirs('hadoop.datanode.data') do
Line 89:   type          :persistent
Line 90:   selects       :all
Line 91:   path          'hadoop/hdfs/data'
Line 92:   mode          "0700"
Line 93: end
Line 94: 
Line 95: # Mapred job scratch space striped across all scratch dirs
Line 96: volume_dirs('hadoop.tasktracker.scratch') do
Line 97:   type          :local
Line 98:   selects       :all
Line 99:   path          'hadoop/mapred/local'
Line 100:   mode          "0755"
Line 101: end
Line 102: 
Line 103: # Hadoop tmp storage on a single scratch dir
Line 104: volume_dirs('hadoop.tmp') do
Line 105:   type          :local
Line 106:   selects       :single
Line 107:   path          'hadoop/tmp'
Line 108:   group         'hadoop'
Line 109:   mode          "0777"
Line 110: end
Line 111: 
Line 112: # Hadoop log storage on a single scratch dir
Line 113: volume_dirs('hadoop.log') do
Line 114:   type          :local
Line 115:   selects       :single
Line 116:   path          'hadoop/log'
Line 117:   group         'hadoop'
Line 118:   mode          "0777"
Line 119: end
Line 120: %w[namenode secondarynn datanode].each{|svc| directory("#{node[:hadoop][:log_dir]}/#{svc}"){ action(:create) ; owner 'hdfs'   ; group "hadoop"; mode "0775" } }
Line 121: %w[jobtracker tasktracker       ].each{|svc| directory("#{node[:hadoop][:log_dir]}/#{svc}"){ action(:create) ; owner 'mapred' ; group "hadoop"; mode "0775" } }
Line 122: 
Line 123: # JMX should listen on the public interface
Line 124: node[:hadoop][:jmx_dash_addr] = public_ip_of(node)
Line 125: 
Line 126: # Make /var/log/hadoop point to the logs (which is on the first scratch dir),
Line 127: # and /var/run/hadoop point to the actual pid dir
Line 128: force_link("/var/log/hadoop",                    node[:hadoop][:log_dir] )
Line 129: force_link("/var/log/#{node[:hadoop][:handle]}", node[:hadoop][:log_dir] )
Line 130: force_link("/var/run/#{node[:hadoop][:handle]}", node[:hadoop][:pid_dir] )
Line 131: 
Line 132: node[:hadoop][:exported_jars] = [
Line 133:   "#{node[:hadoop][:home_dir]}/hadoop-core.jar",
Line 134:   "#{node[:hadoop][:home_dir]}/hadoop-examples.jar",
Line 135:   "#{node[:hadoop][:home_dir]}/hadoop-test.jar",
Line 136:   "#{node[:hadoop][:home_dir]}/hadoop-tools.jar",
Line 137: ]
Line 138: 
Line 139: node[:hadoop][:exported_libs] = Dir["#{node[:hadoop][:home_dir]}/lib/native/**/*.*"].sort.reject{|ff| File.directory?(ff) }
Line 140: 
Line 141: Chef::Log.debug( [ 'hadoop native libs', node[:hadoop][:exported_libs] ].inspect )
Line 142: 
Line 143: node[:hadoop][:exported_confs]  = [
Line 144:   "#{node[:hadoop][:conf_dir]}/core-site.xml",
Line 145:   "#{node[:hadoop][:conf_dir]}/hdfs-site.xml",
Line 146:   "#{node[:hadoop][:conf_dir]}/mapred-site.xml",
Line 147: ]
Line 148: 
Line 149: 

---

### OUTPUT FORMAT

For each detected smell, output a single line in CSV format:
NAME_OF_FILE,LINE_NUMBER,SMELL_CATEGORY

If no smells are found in the file, return:
NAME_OF_FILE,0,none

**Important:** 
- Output only the CSV findings, no additional explanation
- Use the exact smell names from the definitions above
- Focus on identifying actual security vulnerabilities, not potential issues
- Be precise with line number identification